\subsection{Code}

As mentioned in the introduction, our notation is influenced by NumPy and various proposals to implement named axes with NumPy or equivalent libraries in various programming languages. But our proposal here is for mathematical notation to be used in papers and software documentation.

Some might ask, why not simply write code into our papers? One reason is that code is not as concise and readable (in our opinion) as math notation. Another reason is that it's good to have a specification of a model that's independent of the implementation of the model so that the implementation can be checked against the specification.

\subsection{Index notation}

A very frequently asked question is why we haven't used index notation as used in physics, and the Einstein summation convention in particular. In this notation, axes are ordered, and every equation is written in terms of tensor components.
If an index appears on both sides of an equation, then the equation must hold for each value of the index, and if an index appears on only one side of an equation, there is an implicit summation over that index.
\begin{align*}
  \text{Attention} \colon \reals^{n' \times d_k} \times \reals^{n \times d_k} \times \reals^{n \times d_v} &\rightarrow \reals^{n' \times d_v} \\
  \left[\text{Attention}(Q, K, V)\right]_{i'k} &= \softmax_i \left( \frac{Q_{i'j} K_{ij}}{\sqrt{d_k}} \right) V_{ik}.
\end{align*}
We'd have to define exactly what the $i$ under softmax means ($i$ is bound inside the softmax and free outside it), and since softmax doesn't distribute over addition, we'd need to clarify that the implicit summation over $j$ occurs inside the softmax.

Other than that, this is concise and unambiguous. But it doesn't really solve the main problem we set out to solve, which is that ordered axes force the author and reader to remember the purpose of each axis. The indices do act as symbolic names for axes (indeed, in \emph{abstract} index notation, they really are symbols, not variables), but they are temporary names; they could be totally different in the next equation. It would be up to the author to choose to use consistent names, and to do so correctly.

A second issue is that index notation requires us to write out all indices explicitly. So if we wanted to extend attention to multiple heads and minibatches, we would write:
\begin{gather*}
  \text{Attention} \colon \reals^{B \times H \times n' \times d_k} \times \reals^{B \times H \times n \times d_k} \times \reals^{B \times H \times n \times d_v} \rightarrow \reals^{B \times H \times n' \times d_v} \\
  \left[\text{Attention}(Q, K, V)\right]_{bhi'k} = \softmax_i \left( \frac{Q_{bhi'j} K_{bhij}}{\sqrt{d_k}} \right) V_{bhik}.
\end{gather*}
We could adopt a convention that extends a function on tensors to tensors that have extra axes to the \emph{left}, but such conventions tend to lead to messy reordering and squeezing/unsqueezing of axes. Named axes make this unnecessary.


