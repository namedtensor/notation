\pdfoutput=1
\documentclass[10pt]{article}
\usepackage[accepted]{tmlr} 
\let\authorname\name \let\name\undefined % avoid conflict with our \name macro
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{natbib}

%%% The order of the following is important
\usepackage[hidelinks]{hyperref}
\usepackage{amsthm}
\usepackage[capitalize]{cleveref}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Example}
%%%

% Make DOIs clickable
\newcommand{\doi}[1]{\href{https://doi.org/#1}{doi: #1}}

\usepackage{namedtensor}

\DeclareMathOperator*{\softmax}{softmax}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\restrict}[2]{\mathopen{}\left.#1\right|_{#2}}
\newcommand{\eqby}[1]{\stackrel{\text{(\ref{#1})}}{=}}
\makeatletter
\newcommand\yestag{\incr@eqnum\tag{\number\value{equation}}}
\makeatother
\allowdisplaybreaks

\DeclareMathOperator{\ind}{ind}
\DeclareMathOperator{\rec}{rec}
\DeclareMathOperator{\shp}{shp}
\newcommand{\nmatrix}[3]{#1\begin{array}[b]{@{}c@{}}#2\\\begin{bmatrix}#3\end{bmatrix}\end{array}}
\newcommand{\inax}{^*} % diacritic for input axis in differentiation
\newcommand{\ddx}[1]{\frac{\partial #1}{\partial X\inax}}

% axis names
\ndef{\ax}{ax}
\ndef{\dd}{d}
\ndef{\layer}{layer}
\ndef{\seq}{seq}
\ndef{\subseq}{subseq}
\ndef{\key}{key} \ndef{\val}{val}
\ndef{\heads}{heads}
\ndef{\batch}{batch}
\ndef{\inp}{input} \ndef{\hidden}{hidden} \ndef{\out}{out}
\ndef{\height}{height} \ndef{\width}{width} \ndef{\chans}{chans}
\ndef{\kernel}{kernel} \ndef{\kh}{kh} \ndef{\kw}{kw}
\ndef{\vocab}{vocab}
\ndef{\classes}{classes}
\ndef{\state}{state}
\ndef{\emb}{emb}

\title{Named Tensor Notation}
\author{\authorname David Chiang \\ \addr University of Notre Dame \AND \authorname Alexander M. Rush \\ \addr Cornell University \AND \authorname Boaz Barak \\ \addr Harvard University}
\def\month{12}
\def\year{2022}
\def\openreview{https://openreview.net/forum?id=hVT7SHlilx}

\begin{document}

\maketitle

\begin{abstract}
We propose a notation for tensors with named axes, which relieves the author, reader, and future implementers of machine learning models from the burden of keeping track of the order of axes and the purpose of each. The notation makes it easy to lift operations on low-order tensors to higher order ones, for example, from images to minibatches of images, or from an attention mechanism to multiple attention heads.

After a brief overview and formal definition of the notation, we illustrate it through several examples from modern machine learning, from building blocks like attention and convolution to full models like Transformers and LeNet. We then discuss differential calculus in our notation and compare with some alternative notations. Our proposals build on ideas from many previous papers and software libraries. We hope that our notation will encourage more authors to use named tensors, resulting in clearer papers and more precise implementations.
\end{abstract}

\section{Introduction}
\label{sec:intro}
\input{intro}

\section{Named Tensors}
\input{tensors}

\section{Operations}
\label{sec:operations}
\input{operations}

\section{Worked Examples: Neural Networks}
\label{sec:examples}
\input{examples}

\section{Differential Calculus}
\label{sec:calculus}
\input{calculus}

\section{Alternatives and Related Work}
\input{alternatives}

\section{Conclusions}
\input{conclusion}

\section*{Acknowledgements}

We would like to thank Ekin Aky\"{u}rek, Justin Bayer, Tongfei Chen, Chu-Cheng Lin, Colin McDonald, Adam Poliak, Matt Post, Chung-chieh Shan, Nishant Sinha, and Yee Whye Teh for their input to this document (or the ideas in it). We also thank the anonymous TMLR reviewers for their feedback, which substantially improved the quality of the paper, especially \cref{sec:calculus}.

This material is based upon work supported by the National Science Foundation under Grants No.~CCF-2019291 and~DMS-2134157, as well as Simons Investigator Fellowship, DARPA grant W911NF2010021, and DOE grant DE-SC0022199. 
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies.

\bibliographystyle{tmlr}
\bibliography{references}

\appendix

\section{Extended Examples}
\label{sec:examples_long}
\input{examples_long}

\section{Differentiation: Formal Definitions}
\label{sec:calculus_formal}
\input{calculus_formal}

\input{macros}

\end{document}
