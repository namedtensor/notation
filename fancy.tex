\subsection{Indexing with a tensor of indices}

Contributors: Tongfei Chen and Chu-Cheng Lin

NumPy defines two kinds of \emph{advanced} (also known as \emph{fancy}) indexing: by integer arrays and by Boolean arrays. Here, we generalize indexing by integer arrays to named tensors. That is, if $A$ is a named tensor with $D$ indices and $\iota^1, \ldots, \iota^D$ are named tensors, called ``indexers,'' what is $A_{\iota^1, \ldots, \iota^D}$?

Advanced indexing could be derived by taking a function
\begin{align*}
  \nfun{\ax}{index} \colon F^{\ax[I]} \times I &\rightarrow F \\
  \nfun{\ax}{index}(A, i) &= A_{\ax(i)}
\end{align*}
and extending it to higher-order tensors in its second argument according to the rules in \S\ref{sec:tensorfunctions}. But because that's somewhat abstract, we give a more concrete definition below.

We first consider the case where all the indexers have the same shape $\mathcal{S}$:
\begin{align*}
  A &\in F^{\ax_1[I_1] \times \cdots \times \ax_D[I_D]} \\
  \iota^d &\in I_d^{\mathcal{S}} & d &= 1, \ldots, D.
\end{align*}
Then $A_{\iota^1, \ldots, \iota^D}$ is the named tensor with shape $\mathcal{S}$ such that for any $s \in \rec{\mathcal{S}}$,
\begin{align*}
  [A_{\iota^1, \ldots, \iota^D}]_s &= A_{\iota^1_s, \ldots, \iota^D_s}.
\end{align*}
More generally, suppose the indexers have different but compatible shapes:
\begin{align*}
  A &\in F^{\ax_1[I_1] \times \cdots \times \ax_D[I_D]} \\
  \iota^d &\in I_d^{\mathcal{S}_d} & d &= 1, \ldots, D
\end{align*}
where the $\mathcal{S}_d$ are pairwise compatible. Then $A_{\iota^1, \ldots, \iota^D}$ is the named tensor with shape $\mathcal{S} = \bigcup_d \mathcal{S}_d$ such that for any $s \in \rec{\mathcal{S}}$,
\begin{align*}
  [A_{\iota^1, \ldots, \iota^D}]_s &= A_{\iota^1_{\restrict{s}{\mathcal{S}_1}}, \ldots, \iota^D_{\restrict{s}{\mathcal{S}_D}}}.
\end{align*}

Let's consider a concrete example in natural language processing. Consider a batch of sentences encoded as a sequence of word vectors, that is, a tensor $X \in \mathbb{R}^{\batch(B) \times \sent(N) \times \emb(E)}$. For each sentence, we would like to take out the encodings of a particular span for each sentence $b \in [B]$ in the batch, resulting in a tensor $Y \in \mathbb{R}^{\batch(B) \times \subseq(M) \times \emb(E)}$.

We create a indexer for the $\sent$ axis: $\iota \in [N]^{\batch(B) \times \subseq(M)}$ that selects the desired tokens. Also define the function
\begin{align*}
  \nfun{\ax}{arange}(I) &\in I^{\ax[I]} \\
  \left[\nfun{\ax}{arange}(I)\right]_{\ax(i)} &= i
\end{align*}
which generalizes the NumPy function of the same name.

Then we can write
\begin{equation*}
  Y = X_{\batch(\iota), \sent(\nfun{\sent}{arange}(n)), \emb(\nfun{\emb}{arange}(E))}.
\end{equation*}
