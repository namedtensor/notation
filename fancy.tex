\subsection{Indexing with a tensor of indices}

Contributors: Tongfei Chen and Chu-Cheng Lin

NumPy defines a kind of \emph{advanced} (also known as \emph{fancy}) indexing in which a tensor is indexed by another tensor of integers. The analogous operation for named tensors turns out to generalize both advanced indexing as well as TensorFlow and PyTorch's \verb|gather| function.

Define
\begin{align*}
  \nfun{\ax}{index} \colon F^{\ax[I]} \times I &\rightarrow F \\
  \nfun{\ax}{index}(A, i) &= A_{\ax(i)}.
\end{align*}
This function can be extended to higher-order tensors in its second argument according to the rules in \S\ref{sec:tensorfunctions}. Then, to enable indexing by integer arrays, we just have to define
\begin{equation*}
  A_{\ax(\iota)} = \nfun{\ax}{index}(A, \iota).
\end{equation*}

There is more to this definition than meets the eye. Suppose that $A$ has shape $\ax_1$ and $\iota$ has shape $\ax_2 \times \ax_3$. Then $A_{\ax_1(\iota)}$ has shape $\ax_2 \times \ax_3$ and
\begin{equation*}
  [A_{\ax_1(\iota)}]_{\ax_2(i),\ax_3(j)} = A_{\ax_1(\iota_{\ax_2(i),\ax_3(j)})}
\end{equation*}
which is analogous to NumPy's advanced indexing. On the other hand, suppose that $A$ has shape $\ax_1 \times \ax_2 \times \ax_3$ and $\iota$ again has shape $\ax_2 \times \ax_3$. Then $A_{\ax_1(\iota)}$ again has shape $\ax_2 \times \ax_3$, but
\begin{equation*}
  [A_{\ax_1(\iota)}]_{\ax_2(i),\ax_3(j)} = A_{\ax_1(\iota_{\ax_2(i),\ax_3(j)}),\ax_2(i),\ax_3(j)}
\end{equation*}
which is analogous to \verb|gather|.

\ndef{\subseq}{subseq}

Let's consider a concrete example in natural language processing. Consider a batch of sentences encoded as a sequence of word vectors, that is, a tensor $X \in \mathbb{R}^{\batch[B] \times \seq[N] \times \emb[E]}$. For each sentence in the batch, we would like to take out the encodings of some subsequence (possibly different for each sentence), resulting in a tensor $Y \in \mathbb{R}^{\batch[B] \times \subseq[M] \times \emb[E]}$.

We create a indexer for the $\seq$ axis: $\iota \in [N]^{\batch[B] \times \subseq[M]}$ that selects the desired positions. Then we can write
\begin{equation*}
  Y = X_{\seq(\iota)}
\end{equation*}
which is equivalent to the much more complicated expression
\begin{equation*}
  Y_{\batch(b),\subseq(i)} = X_{\batch(b),\seq(\iota_{\batch(b),\subseq(i)})}.
\end{equation*}
